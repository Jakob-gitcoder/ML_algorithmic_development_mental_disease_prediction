{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b29124-6e43-4481-9307-55874d3578fb",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c944a6f-201f-4f97-ab1d-8a24132dd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Installing libraries without displaying output\n",
    "!pip install scikit-learn\n",
    "!pip install missingno\n",
    "!pip install xgboost\n",
    "!pip install imbalanced-learn\n",
    "!pip install fancyimpute\n",
    "!pip install tensorflow\n",
    "!pip install tabulate\n",
    "!pip install statsmodels\n",
    "!pip install lightgbm\n",
    "#!pip install yellowbrick\n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4a547f-58f5-4fc1-bf59-cf40be6daf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from yellowbrick.features import RFECV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a4133-8305-4812-8dd2-7c8d2c6daff0",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ceca05-dfe6-4ab9-87b6-36e6d9b00348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anxiety ------------------------------------\n",
    "# loading feature engineered variables\n",
    "anx_data=pd.read_csv('df_anx_t6_2.csv')\n",
    "\n",
    "# Loading in data\n",
    "X_anx = anx_data.iloc[:, :-1]\n",
    "y_anx = anx_data.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Distressed ---------------------------------\n",
    "# loading feature engineered variables\n",
    "dis_data=pd.read_csv('data_2.csv')\n",
    "\n",
    "\n",
    "# Loading in data\n",
    "X_dis = dis_data.iloc[:, :-1]\n",
    "y_dis = dis_data.iloc[:, -1]\n",
    "\n",
    "# Removing redundant feature\n",
    "X_dis = X_dis.drop(X_dis.columns[0], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f6e9dd5-37c5-4c3a-b35f-4d39254fd35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24cd74f-afc8-474d-82b3-0ae1d7d7ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb7531-3011-41af-afe0-91cc2e66b9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e61c1f-11ad-4c0d-a3ec-cd4abf6f05ba",
   "metadata": {},
   "source": [
    "# Scaling analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd301ca-78bf-47ad-a498-97e5d25dca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# default models\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_jobs=-1)),\n",
    "    ('XGB', xgb.XGBClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('LGBM', LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)),\n",
    "    ('MLP', MLPClassifier(random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94893fd3-a639-4ed8-8eb1-43621271851f",
   "metadata": {},
   "source": [
    "## Anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed6ff4a0-fe8d-4197-9ae7-3f3d0ca072db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest, Scaler: StandardScaler, F1-macro: 0.8273 +/- 0.0529\n",
      "Model: Random Forest, Scaler: MinMaxScaler, F1-macro: 0.8273 +/- 0.0529\n",
      "Model: Random Forest, Scaler: RobustScaler, F1-macro: 0.8273 +/- 0.0529\n",
      "Model: Random Forest, Scaler: QuantileTransformer, F1-macro: 0.8273 +/- 0.0529\n",
      "Model: XGB, Scaler: StandardScaler, F1-macro: 0.8405 +/- 0.0790\n",
      "Model: XGB, Scaler: MinMaxScaler, F1-macro: 0.8405 +/- 0.0790\n",
      "Model: XGB, Scaler: RobustScaler, F1-macro: 0.8405 +/- 0.0790\n",
      "Model: XGB, Scaler: QuantileTransformer, F1-macro: 0.8405 +/- 0.0790\n",
      "Model: LGBM, Scaler: StandardScaler, F1-macro: 0.8419 +/- 0.0699\n",
      "Model: LGBM, Scaler: MinMaxScaler, F1-macro: 0.8641 +/- 0.0834\n",
      "Model: LGBM, Scaler: RobustScaler, F1-macro: 0.8362 +/- 0.0724\n",
      "Model: LGBM, Scaler: QuantileTransformer, F1-macro: 0.8621 +/- 0.0858\n",
      "Model: Decision Tree, Scaler: StandardScaler, F1-macro: 0.7878 +/- 0.0725\n",
      "Model: Decision Tree, Scaler: MinMaxScaler, F1-macro: 0.7878 +/- 0.0725\n",
      "Model: Decision Tree, Scaler: RobustScaler, F1-macro: 0.7878 +/- 0.0725\n",
      "Model: Decision Tree, Scaler: QuantileTransformer, F1-macro: 0.7772 +/- 0.0835\n"
     ]
    }
   ],
   "source": [
    "# Defining 4 scalers, standard, minmax, robust and quantile:\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppressing all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Defining the list of models, scalers, and imputers\n",
    "\n",
    "# models that work with missing values\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGB', xgb.XGBClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('LGBM', LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# models that dont work with missing values\n",
    "models_nan = [\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_jobs=-1)),\n",
    "    ('MLP', MLPClassifier(random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "]\n",
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'QuantileTransformer': QuantileTransformer()\n",
    "}\n",
    "\n",
    "# Performing cross-validation for each model, scaler, and imputer\n",
    "for model_name, model in models:\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', scaler),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(pipeline, X_anx, y_anx, cv=cv, scoring='f1_macro')\n",
    "        print(f\"Model: {model_name}, Scaler: {scaler_name}, F1-macro: {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dee31a2d-5d86-4682-9efd-d091f31b01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM, Scaler: StandardScaler, F1-macro: 0.7882 +/- 0.0859\n",
      "Model: SVM, Scaler: MinMaxScaler, F1-macro: 0.8490 +/- 0.1264\n",
      "Model: SVM, Scaler: RobustScaler, F1-macro: 0.8249 +/- 0.0721\n",
      "Model: SVM, Scaler: QuantileTransformer, F1-macro: 0.6937 +/- 0.0840\n",
      "Model: KNN, Scaler: StandardScaler, F1-macro: 0.7943 +/- 0.1109\n",
      "Model: KNN, Scaler: MinMaxScaler, F1-macro: 0.6606 +/- 0.1324\n",
      "Model: KNN, Scaler: RobustScaler, F1-macro: 0.7584 +/- 0.1300\n",
      "Model: KNN, Scaler: QuantileTransformer, F1-macro: 0.7262 +/- 0.1670\n",
      "Model: MLP, Scaler: StandardScaler, F1-macro: 0.7712 +/- 0.1152\n",
      "Model: MLP, Scaler: MinMaxScaler, F1-macro: 0.8346 +/- 0.1039\n",
      "Model: MLP, Scaler: RobustScaler, F1-macro: 0.7968 +/- 0.1006\n",
      "Model: MLP, Scaler: QuantileTransformer, F1-macro: 0.8318 +/- 0.0909\n",
      "Model: Naive Bayes, Scaler: StandardScaler, F1-macro: 0.6962 +/- 0.0382\n",
      "Model: Naive Bayes, Scaler: MinMaxScaler, F1-macro: 0.7268 +/- 0.0482\n",
      "Model: Naive Bayes, Scaler: RobustScaler, F1-macro: 0.7337 +/- 0.0356\n",
      "Model: Naive Bayes, Scaler: QuantileTransformer, F1-macro: 0.7470 +/- 0.0719\n",
      "Model: Logistic Regression, Scaler: StandardScaler, F1-macro: 0.7844 +/- 0.1331\n",
      "Model: Logistic Regression, Scaler: MinMaxScaler, F1-macro: 0.8413 +/- 0.0956\n",
      "Model: Logistic Regression, Scaler: RobustScaler, F1-macro: 0.8197 +/- 0.0962\n",
      "Model: Logistic Regression, Scaler: QuantileTransformer, F1-macro: 0.8142 +/- 0.1347\n"
     ]
    }
   ],
   "source": [
    "# Performing cross-validation for each model, scaler, and imputer\n",
    "for model_name, model in models_nan:\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', scaler),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(pipeline, X_anx_nan, y_anx_nan, cv=cv, scoring='f1_macro')\n",
    "        print(f\"Model: {model_name}, Scaler: {scaler_name}, F1-macro: {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c5caa-f669-4ff6-8b48-8c097e469bac",
   "metadata": {},
   "source": [
    "RF - not affected\n",
    "\n",
    "XGB - not affected\n",
    "\n",
    "LGBM - MinMax\n",
    "\n",
    "DCT - same except Quantile-worse\n",
    "\n",
    "SVM - MinMax\n",
    "\n",
    "KNN - standard\n",
    "\n",
    "MLP - MinMax\n",
    "\n",
    "NB - Quantile\n",
    "\n",
    "LGR - MinMax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391c76e-1103-4720-9157-c37874970a6a",
   "metadata": {},
   "source": [
    "## Distressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b44d18ec-972f-44a6-b104-9ec2376065d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest, Scaler: StandardScaler, F1-macro: 0.8162 +/- 0.1287\n",
      "Model: Random Forest, Scaler: MinMaxScaler, F1-macro: 0.8090 +/- 0.1208\n",
      "Model: Random Forest, Scaler: RobustScaler, F1-macro: 0.8090 +/- 0.1208\n",
      "Model: Random Forest, Scaler: QuantileTransformer, F1-macro: 0.8162 +/- 0.1287\n",
      "Model: XGB, Scaler: StandardScaler, F1-macro: 0.8334 +/- 0.0927\n",
      "Model: XGB, Scaler: MinMaxScaler, F1-macro: 0.8334 +/- 0.0927\n",
      "Model: XGB, Scaler: RobustScaler, F1-macro: 0.8334 +/- 0.0927\n",
      "Model: XGB, Scaler: QuantileTransformer, F1-macro: 0.8334 +/- 0.0927\n",
      "Model: LGBM, Scaler: StandardScaler, F1-macro: 0.8237 +/- 0.1318\n",
      "Model: LGBM, Scaler: MinMaxScaler, F1-macro: 0.8705 +/- 0.0656\n",
      "Model: LGBM, Scaler: RobustScaler, F1-macro: 0.8323 +/- 0.0921\n",
      "Model: LGBM, Scaler: QuantileTransformer, F1-macro: 0.8431 +/- 0.0952\n",
      "Model: Decision Tree, Scaler: StandardScaler, F1-macro: 0.7756 +/- 0.0523\n",
      "Model: Decision Tree, Scaler: MinMaxScaler, F1-macro: 0.7756 +/- 0.0523\n",
      "Model: Decision Tree, Scaler: RobustScaler, F1-macro: 0.7717 +/- 0.0530\n",
      "Model: Decision Tree, Scaler: QuantileTransformer, F1-macro: 0.7738 +/- 0.0741\n"
     ]
    }
   ],
   "source": [
    "# Defining 4 scalers, standard, minmax, robust and quantile:\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppressing all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Defining the list of models, scalers, and imputers\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGB', xgb.XGBClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('LGBM', LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "models_nan = [\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_jobs=-1)),\n",
    "    ('MLP', MLPClassifier(random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "]\n",
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'QuantileTransformer': QuantileTransformer()\n",
    "}\n",
    "\n",
    "# Performing cross-validation for each model, scaler, and imputer\n",
    "for model_name, model in models:\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', scaler),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(pipeline, X_dis, y_dis, cv=cv, scoring='f1_macro')\n",
    "        print(f\"Model: {model_name}, Scaler: {scaler_name}, F1-macro: {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e887dd67-8c5b-41a9-a514-309e9e12ee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM, Scaler: StandardScaler, F1-macro: 0.8045 +/- 0.1224\n",
      "Model: SVM, Scaler: MinMaxScaler, F1-macro: 0.8383 +/- 0.1312\n",
      "Model: SVM, Scaler: RobustScaler, F1-macro: 0.7960 +/- 0.1065\n",
      "Model: SVM, Scaler: QuantileTransformer, F1-macro: 0.7449 +/- 0.0879\n",
      "Model: KNN, Scaler: StandardScaler, F1-macro: 0.7128 +/- 0.1183\n",
      "Model: KNN, Scaler: MinMaxScaler, F1-macro: 0.6512 +/- 0.1511\n",
      "Model: KNN, Scaler: RobustScaler, F1-macro: 0.7433 +/- 0.1312\n",
      "Model: KNN, Scaler: QuantileTransformer, F1-macro: 0.6736 +/- 0.1360\n",
      "Model: MLP, Scaler: StandardScaler, F1-macro: 0.8074 +/- 0.0757\n",
      "Model: MLP, Scaler: MinMaxScaler, F1-macro: 0.8349 +/- 0.1295\n",
      "Model: MLP, Scaler: RobustScaler, F1-macro: 0.7683 +/- 0.0398\n",
      "Model: MLP, Scaler: QuantileTransformer, F1-macro: 0.7998 +/- 0.0843\n",
      "Model: Naive Bayes, Scaler: StandardScaler, F1-macro: 0.7172 +/- 0.0671\n",
      "Model: Naive Bayes, Scaler: MinMaxScaler, F1-macro: 0.7281 +/- 0.0658\n",
      "Model: Naive Bayes, Scaler: RobustScaler, F1-macro: 0.7281 +/- 0.0658\n",
      "Model: Naive Bayes, Scaler: QuantileTransformer, F1-macro: 0.7398 +/- 0.0811\n",
      "Model: Logistic Regression, Scaler: StandardScaler, F1-macro: 0.8588 +/- 0.0497\n",
      "Model: Logistic Regression, Scaler: MinMaxScaler, F1-macro: 0.8343 +/- 0.1250\n",
      "Model: Logistic Regression, Scaler: RobustScaler, F1-macro: 0.8564 +/- 0.0574\n",
      "Model: Logistic Regression, Scaler: QuantileTransformer, F1-macro: 0.8029 +/- 0.1031\n"
     ]
    }
   ],
   "source": [
    "# Performing cross-validation for each model, scaler, and imputer\n",
    "for model_name, model in models_nan:\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', scaler),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(pipeline, X_dis_nan, y_dis_nan, cv=cv, scoring='f1_macro')\n",
    "        print(f\"Model: {model_name}, Scaler: {scaler_name}, F1-macro: {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a357b5-3352-4553-a686-30a4135e3524",
   "metadata": {},
   "source": [
    "RF - standard or quantile\n",
    "\n",
    "XGB - not affected\n",
    "\n",
    "LGBM - MinMax\n",
    "\n",
    "DCT - Standard or MinMax\n",
    "\n",
    "SVM - MinMax\n",
    "\n",
    "KNN - Robust\n",
    "\n",
    "MLP - MinMax\n",
    "\n",
    "NB - Quantile\n",
    "\n",
    "LGR - Standard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
